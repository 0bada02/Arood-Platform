{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aebf99-682b-4843-a500-18307c659811",
   "metadata": {},
   "source": [
    "# Load Arood Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aeef87-82e0-4fd2-8fa6-ad76d88c4c4c",
   "metadata": {},
   "source": [
    "## Imoprts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "befc6ef5-9eda-41c5-af7e-cd34b4c14a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shap\n",
    "from random import shuffle\n",
    "from pyarabic import araby\n",
    "from tensorflow.keras.layers import GRU, Embedding, Dense, Input, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e547b1d-3bf2-4967-b949-87a36c67c54e",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499bbf8-0500-40c7-9357-862bff84a2f5",
   "metadata": {},
   "source": [
    "### Read label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a19108-9a0a-44e5-bd02-8300b109801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = os.path.join('./final_baits', 'labels.txt')\n",
    "with open(label_file, 'r') as f:\n",
    "    label2name = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e7976-a51b-4aa3-8c09-f73cd43324e2",
   "metadata": {},
   "source": [
    "### Preprocessing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e02d9d-6a06-4309-a2a1-df4c4f766aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_prosody(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # Handle rare edge cases\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Rule handling improvements (combine related regexes, optimize processing)\n",
    "    text = re.sub(r'[ًٌٍ]', 'ن', text)  # Tanween normalization\n",
    "    text = re.sub(r'(.)ّ', r'\\1\\1', text)  # Handle Shadda\n",
    "    text = re.sub(r'\\bال([تثدذرشصضطظلن])', r'ا\\1', text)  # Solar Lam simplification\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febfe8d7-9860-4718-88e8-3156b89a9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path, on_shatrs=False):\n",
    "    global vocab\n",
    "    text = \"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    # Read the file with UTF-8 encoding\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        t = file.read()\n",
    "\n",
    "    t = preprocess_prosody(t)\n",
    "    t = araby.strip_tatweel(t)\n",
    "    \n",
    "    # Remove unwanted characters\n",
    "    excluded_chars = '!()*-ـ.:=o[]«»;؛,،~?؟\\u200f\\ufeffـ\\xa0'\n",
    "    cleaned_text = ''.join([char for char in t if char not in excluded_chars])\n",
    "    \n",
    "    text += cleaned_text\n",
    "    baits = cleaned_text.split('\\n')\n",
    "    for line in baits:\n",
    "        if len(line) <= 1:  # Skip empty or short lines\n",
    "            continue\n",
    "        label, bait = line.split(' ', 1)  # Split label and text\n",
    "        label = int(label)\n",
    "        bait = bait.strip()\n",
    "        if on_shatrs:\n",
    "            # Further split text into parts (shatrs)\n",
    "            shatrs = bait.split('#')\n",
    "            for shatr in shatrs:\n",
    "                X.append(shatr.strip())\n",
    "                y.append(label)\n",
    "        else:\n",
    "            X.append(bait.strip())\n",
    "            y.append(label)\n",
    "    \n",
    "    # Create a sorted vocabulary from the dataset\n",
    "    vocab = sorted(set(' '.join(X)))\n",
    "\n",
    "    # Shuffle the data to avoid order bias\n",
    "    X, y = shuffle(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a83875-f5a3-4584-ae0c-124bcda35122",
   "metadata": {},
   "source": [
    "### Read Train Data & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae3fedc-b74d-4d10-90fa-80c89e2a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join('./final_baits', 'train.txt')\n",
    "test_file = os.path.join('./final_baits', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fca4a1-b8c4-44d8-a449-1f049ac158cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_data(train_file, on_shatrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066d773a-05c6-4259-8ed7-5f9a705bbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba45fe96-04c6-4b49-9717-0a4293457701",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = extract_data(test_file, on_shatrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e34223-5f9b-4bb6-b889-f4a9f890cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i+1 for i, u in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0465ae-952e-4414-84d0-7ccc64592099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(X):\n",
    "  X = [[char2idx[char] for char in line] for line in X]\n",
    "  X = pad_sequences(X, padding='post', value=0, maxlen = 100)\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5769b63b-aeb8-4cd6-856f-b3c0f9429f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_sequences(X_train)\n",
    "X_valid = to_sequences(X_valid)\n",
    "X_test = to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b189a37-0ecb-4aa1-9eed-f522957472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e299b1-5323-4d6a-addf-97d1affcd964",
   "metadata": {},
   "source": [
    "## Load AroodV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd45d01-8d56-4eb1-a15f-b99be38c7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "AroodV1 = tf.keras.models.load_model('AroodV1.keras')\n",
    "AroodV2 = tf.keras.models.load_model('AroodV2.keras')\n",
    "AroodV3 = tf.keras.models.load_model('AroodV3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a80421-86dc-42ac-9d94-f5c5a96d4572",
   "metadata": {},
   "source": [
    "## Classify Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596e664-a3dd-4c11-942f-910244a3dd91",
   "metadata": {},
   "source": [
    "### classify for AroodV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74761eea-b307-454a-865b-6150562415e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_V1(sentence):\n",
    "    sentence = araby.strip_tashkeel(sentence)\n",
    "    sentence = araby.strip_tatweel(sentence)\n",
    "    sequence = [char2idx[char] for char in sentence]\n",
    "    sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
    "\n",
    "    pred = AroodV1.predict(sequence)[0]\n",
    "    label = label2name[np.argmax(pred, 0).astype('int')]\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    # Instead of print, return the result\n",
    "    return label, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481db21-fa78-47e9-8c6a-511d7dfc0c01",
   "metadata": {},
   "source": [
    "### classify for AroodV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4733e8e9-9939-4746-9660-1039725aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_V2(sentence):\n",
    "    sentence = araby.strip_tatweel(sentence)\n",
    "    sentence = araby.strip_diacritics(sentence)  # Remove diacritics for consistency\n",
    "    sequence = [char2idx.get(char, char2idx.get('<UNK>', 0)) for char in sentence]\n",
    "    sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
    "\n",
    "    pred = AroodV2.predict(sequence)[0]\n",
    "    label = label2name[np.argmax(pred)]\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    # Instead of print, return the result\n",
    "    return label, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ec678-21f7-4ba3-91ab-841eff4e60f8",
   "metadata": {},
   "source": [
    "### classify for AroodV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68dc73d1-5fbf-4fb7-98c2-361e98dcbabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_V3(sentence):\n",
    "    sentence = preprocess_prosody(sentence)\n",
    "    sentence = araby.strip_tatweel(sentence)\n",
    "    sentence = re.sub(r'[\\xa0\\u200b\\u200c]', ' ', sentence)  # Replace non-breaking space and zero-width spaces with regular spaces\n",
    "    sequence = [char2idx[char] for char in sentence]\n",
    "    sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
    "\n",
    "    pred = AroodV3.predict(sequence)[0]\n",
    "    label = label2name[np.argmax(pred, 0).astype('int')]\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    # Instead of print, return the result\n",
    "    return label, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63ccab-cd96-4745-b418-c508bdc402ce",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d220f85b-a634-439d-9e74-64ebeb5ba2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metre(sentence):\n",
    "    # Get predictions and confidences from each model using the classify functions\n",
    "    result_v1 = classify_V1(sentence)  # Returns (label, confidence)\n",
    "    result_v2 = classify_V2(sentence)  # Returns (label, confidence)\n",
    "    result_v3 = classify_V3(sentence)  # Returns (label, confidence)\n",
    "\n",
    "    # Unpack the results\n",
    "    label_v1, confidence_v1 = result_v1\n",
    "    label_v2, confidence_v2 = result_v2\n",
    "    label_v3, confidence_v3 = result_v3\n",
    "\n",
    "    # Print each model's prediction and confidence with full precision\n",
    "    print(f\"AroodV1 predicted: {label_v1} with confidence {confidence_v1*100:.6f}%\")\n",
    "    print(f\"AroodV2 predicted: {label_v2} with confidence {confidence_v2*100:.6f}%\")\n",
    "    print(f\"AroodV3 predicted: {label_v3} with confidence {confidence_v3*100:.6f}%\")\n",
    "\n",
    "    # Initialize variables for best model and corresponding metre\n",
    "    chosen_metre = None\n",
    "    best_model = None\n",
    "    highest_confidence = -1\n",
    "\n",
    "    # Check for similarity in predictions:\n",
    "    similar_models = []\n",
    "\n",
    "    # Compare predictions between models\n",
    "    if label_v1 == label_v2 == label_v3:\n",
    "        similar_models = [(\"AroodV1\", confidence_v1), (\"AroodV2\", confidence_v2), (\"AroodV3\", confidence_v3)]\n",
    "        chosen_metre = label_v1\n",
    "    elif label_v1 == label_v2:\n",
    "        similar_models = [(\"AroodV1\", confidence_v1), (\"AroodV2\", confidence_v2)]\n",
    "        chosen_metre = label_v1\n",
    "    elif label_v1 == label_v3:\n",
    "        similar_models = [(\"AroodV1\", confidence_v1), (\"AroodV3\", confidence_v3)]\n",
    "        chosen_metre = label_v1\n",
    "    elif label_v2 == label_v3:\n",
    "        similar_models = [(\"AroodV2\", confidence_v2), (\"AroodV3\", confidence_v3)]\n",
    "        chosen_metre = label_v2\n",
    "    else:\n",
    "        # No models agree, pick the model with the highest confidence\n",
    "        if confidence_v1 >= max(confidence_v2, confidence_v3):\n",
    "            chosen_metre = label_v1\n",
    "            best_model = \"AroodV1\"\n",
    "            highest_confidence = confidence_v1\n",
    "        elif confidence_v2 >= max(confidence_v1, confidence_v3):\n",
    "            chosen_metre = label_v2\n",
    "            best_model = \"AroodV2\"\n",
    "            highest_confidence = confidence_v2\n",
    "        else:\n",
    "            chosen_metre = label_v3\n",
    "            best_model = \"AroodV3\"\n",
    "            highest_confidence = confidence_v3\n",
    "\n",
    "    # If there were similar models, choose the one with the highest confidence\n",
    "    if similar_models:\n",
    "        best_model, highest_confidence = max(similar_models, key=lambda x: x[1])\n",
    "\n",
    "    print(f\"Predicted metre: {chosen_metre} with highest confidence from {best_model} ({highest_confidence*100:.6f}%)\")\n",
    "\n",
    "    # Return the best model, predicted metre, and highest confidence\n",
    "    return best_model, chosen_metre, highest_confidence * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66439025-0d8e-4d9f-b5c7-b9ced057b7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "AroodV1 predicted: munsareh with confidence 99.986231%\n",
      "AroodV2 predicted: munsareh with confidence 99.988794%\n",
      "AroodV3 predicted: munsareh with confidence 99.958760%\n",
      "Predicted metre: munsareh with highest confidence from AroodV2 (99.988794%)\n"
     ]
    }
   ],
   "source": [
    "chosen_metre = predict_metre(\"قَد طَالَ شَوقِي وَعَادَني طَرَبِي # مِن ذِكِر خَودٍ كَريمَةِ الحَسَبِ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca698b9-1203-48bb-b768-2fd1b92511f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "('munsareh', 0.9998623)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "('munsareh', 0.99988794)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "('munsareh', 0.9995876)\n"
     ]
    }
   ],
   "source": [
    "print(classify_V1(\"قَد طَالَ شَوقِي وَعَادَني طَرَبِي # مِن ذِكِر خَودٍ كَريمَةِ الحَسَبِ\"))\n",
    "print(classify_V2(\"قَد طَالَ شَوقِي وَعَادَني طَرَبِي # مِن ذِكِر خَودٍ كَريمَةِ الحَسَبِ\"))\n",
    "print(classify_V3(\"قَد طَالَ شَوقِي وَعَادَني طَرَبِي # مِن ذِكِر خَودٍ كَريمَةِ الحَسَبِ\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
